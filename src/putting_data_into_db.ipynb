{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7f2959dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine, text\n",
    "from dotenv import load_dotenv\n",
    "from urllib.parse import quote_plus\n",
    "\n",
    "def load_csv_to_postgres():\n",
    "    \"\"\"\n",
    "    Reads a CSV file, adds 'analysis_status' column,\n",
    "    and loads the contents into a PostgreSQL table.\n",
    "    Lets Postgres handle the auto-increment `id`.\n",
    "    \"\"\"\n",
    "    # --- 1. Load config ---\n",
    "    load_dotenv(override=True)\n",
    "\n",
    "    db_user = os.getenv(\"DB_USER\")\n",
    "    db_password = os.getenv(\"DB_PASSWORD\")\n",
    "    db_host = os.getenv(\"DB_HOST\")\n",
    "    db_port = os.getenv(\"DB_PORT\")\n",
    "    db_name = os.getenv(\"DB_NAME\")\n",
    "\n",
    "    csv_file_path = \"data/sampled_amazon_data.csv\"\n",
    "    table_name = \"raw_reviews\"\n",
    "\n",
    "    if not all([db_user, db_password, db_host, db_port, db_name]):\n",
    "        print(\"Error: Database configuration is missing in the .env file.\")\n",
    "        return\n",
    "\n",
    "    try:\n",
    "        # --- 2. Read CSV ---\n",
    "        print(f\"Reading CSV file from '{csv_file_path}'...\")\n",
    "        df = pd.read_csv(csv_file_path)\n",
    "        print(f\"✅ Loaded {len(df)} rows from CSV.\")\n",
    "\n",
    "        # --- 3. Add 'analysis_status' column ---\n",
    "        df[\"analysis_status\"] = \"pending\"\n",
    "\n",
    "        # --- 4. Connect to Postgres ---\n",
    "        encoded_password = quote_plus(db_password)\n",
    "        connection_url = f\"postgresql://{db_user}:{encoded_password}@{db_host}:{db_port}/{db_name}\"\n",
    "        engine = create_engine(connection_url)\n",
    "        print(f\"🔌 Connecting to '{db_name}'...\")\n",
    "\n",
    "        # --- 5. Create table if not exists ---\n",
    "        with engine.connect() as conn:\n",
    "            conn.execute(text(f\"\"\"\n",
    "                CREATE TABLE IF NOT EXISTS {table_name} (\n",
    "                    id SERIAL PRIMARY KEY,\n",
    "                    \"ASIN\" TEXT,\n",
    "                    \"Title\" TEXT,\n",
    "                    \"Description\" TEXT,\n",
    "                    \"ImageURL\" TEXT,\n",
    "                    \"Rating\" FLOAT,\n",
    "                    \"Verified\" BOOLEAN,\n",
    "                    \"ReviewTime\" TIMESTAMP,\n",
    "                    \"Review\" TEXT,\n",
    "                    \"Summary\" TEXT,\n",
    "                    \"Domestic Shipping\" TEXT,\n",
    "                    \"International Shipping\" TEXT,\n",
    "                    \"Sentiment\" FLOAT,\n",
    "                    \"Region\" TEXT,\n",
    "                    analysis_status TEXT\n",
    "                );\n",
    "            \"\"\"))\n",
    "            conn.commit()\n",
    "\n",
    "        # --- 6. Append data to table ---\n",
    "        print(f\"📥 Loading data into '{table_name}'...\")\n",
    "\n",
    "        # --- Change ReviewTime to to latest by shifting the time ---\n",
    "        \n",
    "        # convert ReviewTime into date format then find the lastest date from df['ReviewTime']\n",
    "        df['ReviewTime'] = pd.to_datetime(df['ReviewTime'], errors='coerce')\n",
    "        latest_date = df['ReviewTime'].max()\n",
    "\n",
    "        # find the no. of days from today\n",
    "        days_diff = (pd.Timestamp.now() - latest_date).days\n",
    "\n",
    "        # increment the each ReviewTime by days_diff -1\n",
    "        df['ReviewTime'] = df['ReviewTime'] + pd.Timedelta(days=days_diff - 1)\n",
    "        # so, the latest ReviewTime is now the yesterday's date\n",
    "\n",
    "        df.to_sql(\n",
    "            name=table_name,\n",
    "            con=engine,\n",
    "            if_exists=\"append\",\n",
    "            index=False\n",
    "        )\n",
    "\n",
    "        print(f\"✅ Success! {len(df)} rows inserted into '{table_name}'.\")\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(f\"❌ Error: CSV file '{csv_file_path}' not found.\")\n",
    "    except Exception as e:\n",
    "        print(f\"❌ An error occurred: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a91e1736",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading CSV file from 'data/sampled_amazon_data.csv'...\n",
      "✅ Loaded 200 rows from CSV.\n",
      "🔌 Connecting to 'cx_hackathon_db'...\n",
      "📥 Loading data into 'raw_reviews'...\n",
      "✅ Success! 200 rows inserted into 'raw_reviews'.\n"
     ]
    }
   ],
   "source": [
    "load_csv_to_postgres()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a233ef9",
   "metadata": {},
   "source": [
    "## Getting Data from Postgres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "923d72d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine, engine as sqlalchemy_engine\n",
    "from dotenv import load_dotenv\n",
    "from urllib.parse import quote_plus\n",
    "from typing import Optional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e81abb20",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_db_engine() -> Optional[sqlalchemy_engine.Engine]:\n",
    "    \"\"\"\n",
    "    Reads database credentials from the .env file and creates a\n",
    "    SQLAlchemy engine.\n",
    "\n",
    "    Returns:\n",
    "        sqlalchemy_engine.Engine: A SQLAlchemy engine instance, or None if config is missing.\n",
    "    \"\"\"\n",
    "\n",
    "    load_dotenv()\n",
    "\n",
    "    db_user = os.getenv(\"DB_USER\")\n",
    "    db_password = os.getenv(\"DB_PASSWORD\")\n",
    "    db_host = os.getenv(\"DB_HOST\")\n",
    "    db_port = os.getenv(\"DB_PORT\")\n",
    "    db_name = os.getenv(\"DB_NAME\")\n",
    "\n",
    "    if not all([db_user, db_password, db_host, db_port, db_name]):\n",
    "        print(\"Error: Database configuration is missing in the .env file.\")\n",
    "        return None\n",
    "    \n",
    "    try:\n",
    "        encoded_password = quote_plus(db_password)\n",
    "        connection_url = f\"postgresql://{db_user}:{encoded_password}@{db_host}:{db_port}/{db_name}\"\n",
    "        engine = create_engine(connection_url)\n",
    "        # Test the connection to ensure it's valid\n",
    "        engine.connect()\n",
    "        return engine\n",
    "    except Exception as e:\n",
    "        print(f\"Error creating database engine: {e}\")\n",
    "        return None\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "906eac58",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def fetch_pending_reviews_from_sql(engine: sqlalchemy_engine.Engine, limit: int = 100) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Fetches a batch of reviews with 'pending' status using a provided database engine.\n",
    "\n",
    "    Args:\n",
    "        engine: An active SQLAlchemy engine.\n",
    "        limit (int): The maximum number of reviews to fetch.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: A pandas DataFrame containing the pending reviews.\n",
    "    \"\"\"\n",
    "    table_name = \"raw_reviews\"\n",
    "    sql_query = f\"\"\"\n",
    "        SELECT * FROM {table_name} \n",
    "        WHERE analysis_status = 'pending' \n",
    "        LIMIT {limit};\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        print(f\"Fetching up to {limit} pending reviews...\")\n",
    "        df = pd.read_sql_query(sql_query, engine)\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching data: {e}\")\n",
    "        return pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e5e26d2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting to the database\n",
      "Connection successful.\n",
      "Fetching up to 2000 pending reviews...\n",
      "\n",
      "✅ Success! Fetched 200 pending reviews.\n",
      "--- DataFrame Head ---\n",
      "         ASIN                                              Title  \\\n",
      "0  B002K6AHQY   CND Vinylux Weekly Nail Polish, Rock Royalty,...   \n",
      "1  B00176GSEI  HOT TOOLS Professional 24k Gold Extra-Long Bar...   \n",
      "2  B000ASDGK8                   BaBylissPRO Ceramix Xtreme Dryer   \n",
      "3  B002K6AHQY   CND Vinylux Weekly Nail Polish, Rock Royalty,...   \n",
      "4  B00FYSZDQ4                            COLOR WOW Root Cover Up   \n",
      "\n",
      "                                         Description  \\\n",
      "0  Vinylux weekly polish and weekly top coat are ...   \n",
      "1  Hot Tools Professional 1110 Curling Iron with ...   \n",
      "2  2000 Watt ceramic technology dryer with concen...   \n",
      "3  Vinylux weekly polish and weekly top coat are ...   \n",
      "4  Color Wow root cover up, winner of 44 major be...   \n",
      "\n",
      "                                            ImageURL  Rating  Verified  \\\n",
      "0  https://images-na.ssl-images-amazon.com/images...     3.0      True   \n",
      "1  https://images-na.ssl-images-amazon.com/images...     5.0      True   \n",
      "2  https://images-na.ssl-images-amazon.com/images...     5.0      True   \n",
      "3  https://images-na.ssl-images-amazon.com/images...     2.0      True   \n",
      "4  https://images-na.ssl-images-amazon.com/images...     5.0      True   \n",
      "\n",
      "   ReviewTime                                             Review  \\\n",
      "0  2015-10-19               This color not as good as the others   \n",
      "1  2015-11-17  I've been using this curling iron for YEARS an...   \n",
      "2  2015-09-30  I think it works well and I love it. Much bett...   \n",
      "3  2015-07-03  Not my favorite color. I expected more yellow ...   \n",
      "4  2015-04-16  Was recommended by a friend .  Easy to apply. ...   \n",
      "\n",
      "                       Summary  \\\n",
      "0                  Three Stars   \n",
      "1        The Best Curling Iron   \n",
      "2                   Five Stars   \n",
      "3  Just eh. Beware of shimmer.   \n",
      "4                 nice product   \n",
      "\n",
      "                                   Domestic Shipping  \\\n",
      "0  Currently, item can be shipped only within the...   \n",
      "1                                               None   \n",
      "2                                               None   \n",
      "3  Currently, item can be shipped only within the...   \n",
      "4                                               None   \n",
      "\n",
      "                              International Shipping  Sentiment  \\\n",
      "0  This item is not eligible for international sh...        NaN   \n",
      "1                                               None        1.0   \n",
      "2                                               None        1.0   \n",
      "3  This item is not eligible for international sh...       -1.0   \n",
      "4                                               None        1.0   \n",
      "\n",
      "  analysis_status  \n",
      "0         pending  \n",
      "1         pending  \n",
      "2         pending  \n",
      "3         pending  \n",
      "4         pending  \n"
     ]
    }
   ],
   "source": [
    "print(\"Connecting to the database\")\n",
    "db_engine = create_db_engine()\n",
    "\n",
    "if db_engine:\n",
    "    print(\"Connection successful.\")\n",
    "    pending_reviews_df = fetch_pending_reviews_from_sql(engine=db_engine, limit=2000)\n",
    "    \n",
    "    if not pending_reviews_df.empty:\n",
    "            print(f\"\\n✅ Success! Fetched {len(pending_reviews_df)} pending reviews.\")\n",
    "            print(\"--- DataFrame Head ---\")\n",
    "            print(pending_reviews_df.head())\n",
    "    else:\n",
    "        print(\"\\nNo pending reviews found or an error occurred during fetching.\")\n",
    "else:\n",
    "    print(\"Could not create database engine. Aborting.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a6644ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "e0feba4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "PATH = \"/Users/nike/Downloads/meta_Luxury_Beauty.json.gz\"\n",
    "\n",
    "df = pd.read_json(PATH, lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "7c3c621c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>tech1</th>\n",
       "      <th>description</th>\n",
       "      <th>fit</th>\n",
       "      <th>title</th>\n",
       "      <th>also_buy</th>\n",
       "      <th>tech2</th>\n",
       "      <th>brand</th>\n",
       "      <th>feature</th>\n",
       "      <th>rank</th>\n",
       "      <th>also_view</th>\n",
       "      <th>details</th>\n",
       "      <th>main_cat</th>\n",
       "      <th>similar_item</th>\n",
       "      <th>date</th>\n",
       "      <th>price</th>\n",
       "      <th>asin</th>\n",
       "      <th>imageURL</th>\n",
       "      <th>imageURLHighRes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "      <td>[After a long day of handling thorny situation...</td>\n",
       "      <td></td>\n",
       "      <td>Crabtree &amp;amp; Evelyn - Gardener's Ultra-Moist...</td>\n",
       "      <td>[B00GHX7H0A, B00FRERO7G, B00R68QXCS, B000Z65AZ...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "      <td>4,324 in Beauty &amp; Personal Care (</td>\n",
       "      <td>[B00FRERO7G, B00GHX7H0A, B07GFHJRMX, B00TJ3NBN...</td>\n",
       "      <td>{'\n",
       "    Product Dimensions: \n",
       "    ': '2.2 x 2.2 ...</td>\n",
       "      <td>Luxury Beauty</td>\n",
       "      <td></td>\n",
       "      <td>NaT</td>\n",
       "      <td>$30.00</td>\n",
       "      <td>B00004U9V2</td>\n",
       "      <td>[https://images-na.ssl-images-amazon.com/image...</td>\n",
       "      <td>[https://images-na.ssl-images-amazon.com/image...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "      <td>[If you haven't experienced the pleasures of b...</td>\n",
       "      <td></td>\n",
       "      <td>AHAVA Bath Salts</td>\n",
       "      <td>[]</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "      <td>1,633,549 in Beauty &amp; Personal Care (</td>\n",
       "      <td>[]</td>\n",
       "      <td>{'\n",
       "    Product Dimensions: \n",
       "    ': '3 x 3.5 x ...</td>\n",
       "      <td>Luxury Beauty</td>\n",
       "      <td></td>\n",
       "      <td>NaT</td>\n",
       "      <td></td>\n",
       "      <td>B0000531EN</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  category tech1                                        description fit  \\\n",
       "0       []        [After a long day of handling thorny situation...       \n",
       "1       []        [If you haven't experienced the pleasures of b...       \n",
       "\n",
       "                                               title  \\\n",
       "0  Crabtree &amp; Evelyn - Gardener's Ultra-Moist...   \n",
       "1                                   AHAVA Bath Salts   \n",
       "\n",
       "                                            also_buy tech2 brand feature  \\\n",
       "0  [B00GHX7H0A, B00FRERO7G, B00R68QXCS, B000Z65AZ...                  []   \n",
       "1                                                 []                  []   \n",
       "\n",
       "                                    rank  \\\n",
       "0      4,324 in Beauty & Personal Care (   \n",
       "1  1,633,549 in Beauty & Personal Care (   \n",
       "\n",
       "                                           also_view  \\\n",
       "0  [B00FRERO7G, B00GHX7H0A, B07GFHJRMX, B00TJ3NBN...   \n",
       "1                                                 []   \n",
       "\n",
       "                                             details       main_cat  \\\n",
       "0  {'\n",
       "    Product Dimensions: \n",
       "    ': '2.2 x 2.2 ...  Luxury Beauty   \n",
       "1  {'\n",
       "    Product Dimensions: \n",
       "    ': '3 x 3.5 x ...  Luxury Beauty   \n",
       "\n",
       "  similar_item date   price        asin  \\\n",
       "0               NaT  $30.00  B00004U9V2   \n",
       "1               NaT          B0000531EN   \n",
       "\n",
       "                                            imageURL  \\\n",
       "0  [https://images-na.ssl-images-amazon.com/image...   \n",
       "1                                                 []   \n",
       "\n",
       "                                     imageURLHighRes  \n",
       "0  [https://images-na.ssl-images-amazon.com/image...  \n",
       "1                                                 []  "
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "c3119f05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12299, 19)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "72ee9d55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12299, 19)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "\n",
    "def clean_description(desc):\n",
    "    # desc is a list, join to string\n",
    "    text = \" \".join(desc) if isinstance(desc, list) else str(desc)\n",
    "    # Remove HTML tags and links\n",
    "    soup = BeautifulSoup(text, \"html.parser\")\n",
    "    # Remove anchor tags but keep their text\n",
    "    for a in soup.find_all('a'):\n",
    "        a.unwrap()\n",
    "    # Remove any URLs\n",
    "    cleaned = re.sub(r'http\\S+', '', soup.get_text())\n",
    "    return cleaned.strip()\n",
    "\n",
    "df['description'] = df['description'].apply(clean_description)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "0e566f8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1948, 19)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keywords = [\"lotion\", \"cream\", \"dryer\", \"soap\", \"powder\"]\n",
    "filtered_df = df[df['title'].str.contains('|'.join(keywords), case=False, na=False)]\n",
    "filtered_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "47a20d9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(680, 19)"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filter rows where 'description' column contains at least 100 words\n",
    "filtered_df = filtered_df[filtered_df['description'].apply(lambda desc: len(str(desc).split()) >= 100)]\n",
    "filtered_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "98ac5c7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = filtered_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "99171c09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'lotion': np.int64(124),\n",
       " 'cream': np.int64(391),\n",
       " 'dryer': np.int64(41),\n",
       " 'soap': np.int64(65),\n",
       " 'powder': np.int64(63)}"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count how many of each keyword appear in the filtered DataFrame\n",
    "keyword_counts = {k: filtered_df['title'].str.contains(k, case=False).sum() for k in keywords}\n",
    "keyword_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "83c748e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'lotion': np.int64(6),\n",
       " 'cream': np.int64(32),\n",
       " 'dryer': np.int64(5),\n",
       " 'soap': np.int64(1),\n",
       " 'powder': np.int64(6)}"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a sample of 50 from filtered_df (with replacement since dataset is small)\n",
    "sample_df = filtered_df.sample(n=50, replace=False)\n",
    "\n",
    "# Count each keyword presence in the sample as well\n",
    "sample_keyword_counts = {k: sample_df['title'].str.contains(k, case=False).sum() for k in keywords}\n",
    "\n",
    "sample_keyword_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "af25612f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 19)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Let's assume df is the user's full dataframe with 'title'\n",
    "# We'll filter it for the 5 categories\n",
    "keywords = [\"lotion\", \"cream\", \"dryer\", \"soap\", \"powder\"]\n",
    "filtered_full_df = df[df['title'].str.contains('|'.join(keywords), case=False, na=False)].copy()\n",
    "\n",
    "# Assign category label based on keyword match (first match wins)\n",
    "def assign_category(title):\n",
    "    for k in keywords:\n",
    "        if k.lower() in title.lower():\n",
    "            return k\n",
    "    return None\n",
    "\n",
    "filtered_full_df['category'] = filtered_full_df['title'].apply(assign_category)\n",
    "\n",
    "# Counts from real dataset provided by user\n",
    "real_counts = {\n",
    "    'lotion': 416,\n",
    "    'cream': 1080,\n",
    "    'dryer': 99,\n",
    "    'soap': 189,\n",
    "    'powder': 183\n",
    "}\n",
    "total = sum(real_counts.values())\n",
    "\n",
    "# Proportional allocation for sample of 50\n",
    "proportional_alloc = {k: int(round(v/total * 50)) for k,v in real_counts.items()}\n",
    "\n",
    "# Ensure total sums to 50 (fix rounding issue)\n",
    "diff = 50 - sum(proportional_alloc.values())\n",
    "if diff != 0:\n",
    "    # Adjust by adding/subtracting from the largest category\n",
    "    max_cat = max(proportional_alloc, key=proportional_alloc.get)\n",
    "    proportional_alloc[max_cat] += diff\n",
    "\n",
    "# Now draw proportional sample\n",
    "proportional_sample = pd.concat([\n",
    "    filtered_full_df[filtered_full_df['category']==cat].sample(n=n, replace=False)\n",
    "    for cat,n in proportional_alloc.items() if n>0\n",
    "])\n",
    "\n",
    "# Balanced sample (10 per category)\n",
    "balanced_sample = pd.concat([\n",
    "    filtered_full_df[filtered_full_df['category']==cat].sample(n=10, replace=False)\n",
    "    for cat in keywords\n",
    "])\n",
    "balanced_sample.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "a447a796",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'lotion': np.int64(10),\n",
       " 'cream': np.int64(11),\n",
       " 'dryer': np.int64(10),\n",
       " 'soap': np.int64(10),\n",
       " 'powder': np.int64(10)}"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "balanced_keyword_counts = {k: balanced_sample['title'].str.contains(k, case=False).sum() for k in keywords}\n",
    "\n",
    "balanced_keyword_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "11040364",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>tech1</th>\n",
       "      <th>description</th>\n",
       "      <th>fit</th>\n",
       "      <th>title</th>\n",
       "      <th>also_buy</th>\n",
       "      <th>tech2</th>\n",
       "      <th>brand</th>\n",
       "      <th>feature</th>\n",
       "      <th>rank</th>\n",
       "      <th>also_view</th>\n",
       "      <th>details</th>\n",
       "      <th>main_cat</th>\n",
       "      <th>similar_item</th>\n",
       "      <th>date</th>\n",
       "      <th>price</th>\n",
       "      <th>asin</th>\n",
       "      <th>imageURL</th>\n",
       "      <th>imageURLHighRes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11204</th>\n",
       "      <td>lotion</td>\n",
       "      <td></td>\n",
       "      <td>The silicone-free formula was designed specifi...</td>\n",
       "      <td></td>\n",
       "      <td>StriVectin High-Potency Wrinkle Filler Lotion,...</td>\n",
       "      <td>[B078W9WM5L, B078W9FJWH, B00IONTS3K, B01B4OIJ6...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "      <td>163,826 in Beauty &amp; Personal Care (</td>\n",
       "      <td>[B078W9WM5L, B0052P11PG, B01B4OIJ6M, B0012J138...</td>\n",
       "      <td>{'\n",
       "    Product Dimensions: \n",
       "    ': '1.5 x 2.2 ...</td>\n",
       "      <td>Luxury Beauty</td>\n",
       "      <td></td>\n",
       "      <td>NaT</td>\n",
       "      <td>$59.00</td>\n",
       "      <td>B017GZJFV6</td>\n",
       "      <td>[https://images-na.ssl-images-amazon.com/image...</td>\n",
       "      <td>[https://images-na.ssl-images-amazon.com/image...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10828</th>\n",
       "      <td>lotion</td>\n",
       "      <td></td>\n",
       "      <td>For an instant tan with no commitment. Our NEW...</td>\n",
       "      <td></td>\n",
       "      <td>St. Tropez One Night Only Wash Off Face &amp;amp; ...</td>\n",
       "      <td>[B014RFOYOQ, B073WGMJLG, B073WH1Z33, B019QNRWY...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>[]</td>\n",
       "      <td>47,925 in Beauty &amp; Personal Care (</td>\n",
       "      <td>[B014RFOYOQ, B00KSS3MJ0, B073WH1Z33, B01B7JORB...</td>\n",
       "      <td>{'\n",
       "    Product Dimensions: \n",
       "    ': '1.5 x 0.8 ...</td>\n",
       "      <td>Luxury Beauty</td>\n",
       "      <td></td>\n",
       "      <td>NaT</td>\n",
       "      <td>$18.00</td>\n",
       "      <td>B014RFOPKY</td>\n",
       "      <td>[https://images-na.ssl-images-amazon.com/image...</td>\n",
       "      <td>[https://images-na.ssl-images-amazon.com/image...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      category tech1                                        description fit  \\\n",
       "11204   lotion        The silicone-free formula was designed specifi...       \n",
       "10828   lotion        For an instant tan with no commitment. Our NEW...       \n",
       "\n",
       "                                                   title  \\\n",
       "11204  StriVectin High-Potency Wrinkle Filler Lotion,...   \n",
       "10828  St. Tropez One Night Only Wash Off Face &amp; ...   \n",
       "\n",
       "                                                also_buy tech2 brand feature  \\\n",
       "11204  [B078W9WM5L, B078W9FJWH, B00IONTS3K, B01B4OIJ6...                  []   \n",
       "10828  [B014RFOYOQ, B073WGMJLG, B073WH1Z33, B019QNRWY...                  []   \n",
       "\n",
       "                                      rank  \\\n",
       "11204  163,826 in Beauty & Personal Care (   \n",
       "10828   47,925 in Beauty & Personal Care (   \n",
       "\n",
       "                                               also_view  \\\n",
       "11204  [B078W9WM5L, B0052P11PG, B01B4OIJ6M, B0012J138...   \n",
       "10828  [B014RFOYOQ, B00KSS3MJ0, B073WH1Z33, B01B7JORB...   \n",
       "\n",
       "                                                 details       main_cat  \\\n",
       "11204  {'\n",
       "    Product Dimensions: \n",
       "    ': '1.5 x 2.2 ...  Luxury Beauty   \n",
       "10828  {'\n",
       "    Product Dimensions: \n",
       "    ': '1.5 x 0.8 ...  Luxury Beauty   \n",
       "\n",
       "      similar_item date   price        asin  \\\n",
       "11204               NaT  $59.00  B017GZJFV6   \n",
       "10828               NaT  $18.00  B014RFOPKY   \n",
       "\n",
       "                                                imageURL  \\\n",
       "11204  [https://images-na.ssl-images-amazon.com/image...   \n",
       "10828  [https://images-na.ssl-images-amazon.com/image...   \n",
       "\n",
       "                                         imageURLHighRes  \n",
       "11204  [https://images-na.ssl-images-amazon.com/image...  \n",
       "10828  [https://images-na.ssl-images-amazon.com/image...  "
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "balanced_sample.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "07ee12c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "final = balanced_sample[['asin', 'title', 'description', 'imageURLHighRes']]\n",
    "final.reset_index(drop=True, inplace=True)\n",
    "final.to_json(\"/Users/nike/Documents/Data Science Work/Project/Hackthon/CX_Management_project/app/data/product/description.json\", orient=\"records\", lines=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "df0ee4ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to JSON file\n",
    "import json\n",
    "\n",
    "# Convert NaT and NaN to None for JSON serialization\n",
    "balanced_sample_clean = balanced_sample.where(pd.notnull(balanced_sample), None)\n",
    "\n",
    "# Convert datetime columns to string (or None)\n",
    "for col in balanced_sample_clean.select_dtypes(include=[\"datetime64[ns]\"]).columns:\n",
    "    balanced_sample_clean[col] = balanced_sample_clean[col].astype(str)\n",
    "    balanced_sample_clean.loc[balanced_sample_clean[col] == \"NaT\", col] = None\n",
    "\n",
    "# Pick only the first image link from imageURLHighRes (if it's a list)\n",
    "def pick_first_image(images):\n",
    "    if isinstance(images, list) and images:\n",
    "        return images[0]\n",
    "    return images\n",
    "\n",
    "balanced_sample_clean[\"ImageURL\"] = balanced_sample_clean[\"imageURLHighRes\"].apply(pick_first_image)\n",
    "balanced_sample_clean.rename(columns={\"asin\": \"ASIN\", \"title\": \"Title\", \"description\": \"Description\"}, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d07eae21",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "b1342c6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Saved description.json\n"
     ]
    }
   ],
   "source": [
    "balanced_sample_clean = balanced_sample_clean[[\"ASIN\", \"Title\", \"Description\", \"ImageURL\"]]\n",
    "with open(\"/Users/nike/Documents/Data Science Work/Project/Hackthon/CX_Management_project/app/data/product/description.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(balanced_sample_clean.to_dict(orient=\"records\"), f, indent=2, ensure_ascii=False)\n",
    "\n",
    "print(\"✅ Saved description.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "a5d2dd5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 4)"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "balanced_sample_clean.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3158ea6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GenAIProj",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
